{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm ./Idiom_Detection.pdf Model\\ Testing.ipynb\n"
      ],
      "metadata": {
        "id": "WniA-xedd8fa"
      },
      "id": "WniA-xedd8fa",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/YasserAderghal/idiom_detection\n",
        "!mv  idiom_detection/* . \n",
        "!pip install eli5\n",
        "!pip install sklearn-crfsuite\n",
        "#!pip install -U 'scikit-learn<0.24'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "pQUN0mwTcca8"
      },
      "id": "pQUN0mwTcca8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## load WORD2VEC\n",
        "WORD2VEC_FILE = \"/content/drive/MyDrive/Colab Notebooks/word2vec/GoogleNews-vectors-negative300.bin\""
      ],
      "metadata": {
        "id": "QqutqPZWlE_j"
      },
      "id": "QqutqPZWlE_j",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a67c1551-92d6-4590-96cf-3f63f88666b0",
      "metadata": {
        "id": "a67c1551-92d6-4590-96cf-3f63f88666b0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import nltk\n",
        "import eli5\n",
        "import utils\n",
        "from sklearn_crfsuite import CRF\n",
        "from IPython.display import display, HTML\n",
        "import os\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "from nltk.corpus import brown,reuters , gutenberg\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('reuters')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9NI5nTodLsi",
        "outputId": "2b626248-9077-481d-dc42-03c253288cf7"
      },
      "id": "J9NI5nTodLsi",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fb541631-de50-45b4-aa08-bb43ddfcbde6",
      "metadata": {
        "id": "fb541631-de50-45b4-aa08-bb43ddfcbde6"
      },
      "outputs": [],
      "source": [
        "OUTPUT_FILE = \"./data/tagged_sentences_examples\"\n",
        "\n",
        "examples = list(pd.read_csv(\"./data/idiom_example.csv\")[\"sentence\"])\n",
        "\n",
        "\n",
        "\n",
        "sents = [word_tokenize(sent.replace(\"’\", \"'\").replace(\"–\", \"-\")) \\\n",
        "         for sent in examples]\n",
        "\n",
        "#utils.clear_file(OUTPUT_FILE)\n",
        "\n",
        "#success = utils.write_tagged_sentences(sents, OUTPUT_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f20b8e4-985e-4148-a850-61b8facf72e6",
      "metadata": {
        "id": "6f20b8e4-985e-4148-a850-61b8facf72e6"
      },
      "source": [
        "## Building the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e8fff410-33fc-41ba-b419-f7bc0db457b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8fff410-33fc-41ba-b419-f7bc0db457b9",
        "outputId": "2bd48007-2654-45c3-fcbf-66aedc041a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting script execution: 2022-12-30 19:20:22.599690\n",
            "2022-12-30 19:20:24.973351: Tagged 0 of 57340 sentences...\n",
            "2022-12-30 19:20:26.068786: Tagged 500 of 57340 sentences...\n",
            "2022-12-30 19:20:27.083334: Tagged 1000 of 57340 sentences...\n",
            "2022-12-30 19:20:28.070749: Tagged 1500 of 57340 sentences...\n",
            "2022-12-30 19:20:29.101748: Tagged 2000 of 57340 sentences...\n",
            "2022-12-30 19:20:30.175109: Tagged 2500 of 57340 sentences...\n",
            "2022-12-30 19:20:31.203665: Tagged 3000 of 57340 sentences...\n",
            "2022-12-30 19:20:32.183557: Tagged 3500 of 57340 sentences...\n",
            "2022-12-30 19:20:33.216693: Tagged 4000 of 57340 sentences...\n",
            "2022-12-30 19:20:34.210232: Tagged 4500 of 57340 sentences...\n",
            "2022-12-30 19:20:35.249464: Tagged 5000 of 57340 sentences...\n",
            "2022-12-30 19:20:36.278101: Tagged 5500 of 57340 sentences...\n",
            "2022-12-30 19:20:37.279127: Tagged 6000 of 57340 sentences...\n",
            "2022-12-30 19:20:38.298880: Tagged 6500 of 57340 sentences...\n",
            "2022-12-30 19:20:39.313026: Tagged 7000 of 57340 sentences...\n",
            "2022-12-30 19:20:40.361796: Tagged 7500 of 57340 sentences...\n",
            "2022-12-30 19:20:41.390801: Tagged 8000 of 57340 sentences...\n",
            "2022-12-30 19:20:42.428616: Tagged 8500 of 57340 sentences...\n",
            "2022-12-30 19:20:43.489938: Tagged 9000 of 57340 sentences...\n",
            "2022-12-30 19:20:44.551865: Tagged 9500 of 57340 sentences...\n",
            "2022-12-30 19:20:45.623044: Tagged 10000 of 57340 sentences...\n",
            "2022-12-30 19:20:46.686014: Tagged 10500 of 57340 sentences...\n",
            "2022-12-30 19:20:47.692246: Tagged 11000 of 57340 sentences...\n",
            "2022-12-30 19:20:48.735593: Tagged 11500 of 57340 sentences...\n",
            "2022-12-30 19:20:49.771002: Tagged 12000 of 57340 sentences...\n",
            "2022-12-30 19:20:50.805983: Tagged 12500 of 57340 sentences...\n",
            "2022-12-30 19:20:51.762922: Tagged 13000 of 57340 sentences...\n",
            "2022-12-30 19:20:52.756354: Tagged 13500 of 57340 sentences...\n",
            "2022-12-30 19:20:53.806628: Tagged 14000 of 57340 sentences...\n",
            "2022-12-30 19:20:54.841234: Tagged 14500 of 57340 sentences...\n",
            "2022-12-30 19:20:55.879181: Tagged 15000 of 57340 sentences...\n",
            "2022-12-30 19:20:56.946403: Tagged 15500 of 57340 sentences...\n",
            "2022-12-30 19:20:57.929296: Tagged 16000 of 57340 sentences...\n",
            "2022-12-30 19:20:58.982976: Tagged 16500 of 57340 sentences...\n",
            "2022-12-30 19:21:00.013640: Tagged 17000 of 57340 sentences...\n",
            "2022-12-30 19:21:01.068307: Tagged 17500 of 57340 sentences...\n",
            "2022-12-30 19:21:02.447662: Tagged 18000 of 57340 sentences...\n",
            "2022-12-30 19:21:04.285741: Tagged 18500 of 57340 sentences...\n",
            "2022-12-30 19:21:05.364583: Tagged 19000 of 57340 sentences...\n",
            "2022-12-30 19:21:06.449707: Tagged 19500 of 57340 sentences...\n",
            "2022-12-30 19:21:07.486502: Tagged 20000 of 57340 sentences...\n",
            "2022-12-30 19:21:08.531855: Tagged 20500 of 57340 sentences...\n",
            "2022-12-30 19:21:09.538251: Tagged 21000 of 57340 sentences...\n",
            "2022-12-30 19:21:10.543880: Tagged 21500 of 57340 sentences...\n",
            "2022-12-30 19:21:11.601980: Tagged 22000 of 57340 sentences...\n",
            "2022-12-30 19:21:12.620355: Tagged 22500 of 57340 sentences...\n",
            "2022-12-30 19:21:13.701059: Tagged 23000 of 57340 sentences...\n",
            "2022-12-30 19:21:14.735174: Tagged 23500 of 57340 sentences...\n",
            "2022-12-30 19:21:15.742403: Tagged 24000 of 57340 sentences...\n",
            "2022-12-30 19:21:16.788841: Tagged 24500 of 57340 sentences...\n",
            "2022-12-30 19:21:17.802013: Tagged 25000 of 57340 sentences...\n",
            "2022-12-30 19:21:18.826962: Tagged 25500 of 57340 sentences...\n",
            "2022-12-30 19:21:19.893518: Tagged 26000 of 57340 sentences...\n",
            "2022-12-30 19:21:20.936183: Tagged 26500 of 57340 sentences...\n",
            "2022-12-30 19:21:22.045555: Tagged 27000 of 57340 sentences...\n",
            "2022-12-30 19:21:23.079051: Tagged 27500 of 57340 sentences...\n",
            "2022-12-30 19:21:24.121962: Tagged 28000 of 57340 sentences...\n",
            "2022-12-30 19:21:25.188876: Tagged 28500 of 57340 sentences...\n",
            "2022-12-30 19:21:26.183564: Tagged 29000 of 57340 sentences...\n",
            "2022-12-30 19:21:27.245140: Tagged 29500 of 57340 sentences...\n",
            "2022-12-30 19:21:28.346168: Tagged 30000 of 57340 sentences...\n",
            "2022-12-30 19:21:29.428185: Tagged 30500 of 57340 sentences...\n",
            "2022-12-30 19:21:30.528102: Tagged 31000 of 57340 sentences...\n",
            "2022-12-30 19:21:31.567212: Tagged 31500 of 57340 sentences...\n",
            "2022-12-30 19:21:32.590341: Tagged 32000 of 57340 sentences...\n",
            "2022-12-30 19:21:33.585636: Tagged 32500 of 57340 sentences...\n",
            "2022-12-30 19:21:34.638277: Tagged 33000 of 57340 sentences...\n",
            "2022-12-30 19:21:35.698919: Tagged 33500 of 57340 sentences...\n",
            "2022-12-30 19:21:36.749388: Tagged 34000 of 57340 sentences...\n",
            "2022-12-30 19:21:37.822198: Tagged 34500 of 57340 sentences...\n",
            "2022-12-30 19:21:38.886302: Tagged 35000 of 57340 sentences...\n",
            "2022-12-30 19:21:40.006593: Tagged 35500 of 57340 sentences...\n",
            "2022-12-30 19:21:41.125277: Tagged 36000 of 57340 sentences...\n",
            "2022-12-30 19:21:42.183736: Tagged 36500 of 57340 sentences...\n",
            "2022-12-30 19:21:43.222778: Tagged 37000 of 57340 sentences...\n",
            "2022-12-30 19:21:44.220400: Tagged 37500 of 57340 sentences...\n",
            "2022-12-30 19:21:45.227974: Tagged 38000 of 57340 sentences...\n",
            "2022-12-30 19:21:46.183655: Tagged 38500 of 57340 sentences...\n",
            "2022-12-30 19:21:47.088525: Tagged 39000 of 57340 sentences...\n",
            "2022-12-30 19:21:47.988311: Tagged 39500 of 57340 sentences...\n",
            "2022-12-30 19:21:48.970854: Tagged 40000 of 57340 sentences...\n",
            "2022-12-30 19:21:49.945282: Tagged 40500 of 57340 sentences...\n",
            "2022-12-30 19:21:50.879434: Tagged 41000 of 57340 sentences...\n",
            "2022-12-30 19:21:52.163393: Tagged 41500 of 57340 sentences...\n",
            "2022-12-30 19:21:53.105350: Tagged 42000 of 57340 sentences...\n",
            "2022-12-30 19:21:54.070171: Tagged 42500 of 57340 sentences...\n",
            "2022-12-30 19:21:55.032717: Tagged 43000 of 57340 sentences...\n",
            "2022-12-30 19:21:55.967012: Tagged 43500 of 57340 sentences...\n",
            "2022-12-30 19:21:56.910128: Tagged 44000 of 57340 sentences...\n",
            "2022-12-30 19:21:57.827524: Tagged 44500 of 57340 sentences...\n",
            "2022-12-30 19:21:59.359755: Tagged 45000 of 57340 sentences...\n",
            "2022-12-30 19:22:01.145507: Tagged 45500 of 57340 sentences...\n",
            "2022-12-30 19:22:02.636062: Tagged 46000 of 57340 sentences...\n",
            "2022-12-30 19:22:03.516639: Tagged 46500 of 57340 sentences...\n",
            "2022-12-30 19:22:04.457513: Tagged 47000 of 57340 sentences...\n",
            "2022-12-30 19:22:05.344368: Tagged 47500 of 57340 sentences...\n",
            "2022-12-30 19:22:06.259281: Tagged 48000 of 57340 sentences...\n",
            "2022-12-30 19:22:07.178947: Tagged 48500 of 57340 sentences...\n",
            "2022-12-30 19:22:08.072068: Tagged 49000 of 57340 sentences...\n",
            "2022-12-30 19:22:08.993639: Tagged 49500 of 57340 sentences...\n",
            "2022-12-30 19:22:09.901096: Tagged 50000 of 57340 sentences...\n",
            "2022-12-30 19:22:10.819493: Tagged 50500 of 57340 sentences...\n",
            "2022-12-30 19:22:11.741490: Tagged 51000 of 57340 sentences...\n",
            "2022-12-30 19:22:12.643443: Tagged 51500 of 57340 sentences...\n",
            "2022-12-30 19:22:13.631427: Tagged 52000 of 57340 sentences...\n",
            "2022-12-30 19:22:14.584398: Tagged 52500 of 57340 sentences...\n",
            "2022-12-30 19:22:15.496054: Tagged 53000 of 57340 sentences...\n",
            "2022-12-30 19:22:16.465296: Tagged 53500 of 57340 sentences...\n",
            "2022-12-30 19:22:17.365101: Tagged 54000 of 57340 sentences...\n",
            "2022-12-30 19:22:18.275817: Tagged 54500 of 57340 sentences...\n",
            "2022-12-30 19:22:19.184889: Tagged 55000 of 57340 sentences...\n",
            "2022-12-30 19:22:20.101854: Tagged 55500 of 57340 sentences...\n",
            "2022-12-30 19:22:21.012907: Tagged 56000 of 57340 sentences...\n",
            "2022-12-30 19:22:21.978520: Tagged 56500 of 57340 sentences...\n",
            "2022-12-30 19:22:22.925200: Tagged 57000 of 57340 sentences...\n",
            "Finishing script execution: 2022-12-30 19:22:23.571822\n",
            "number of idioms found (ish): 431\n"
          ]
        }
      ],
      "source": [
        "# Brown\n",
        "OUTPUT_FILE = \"./data/tagged_sentences_brown\"\n",
        "\n",
        "sents = brown.sents()\n",
        "\n",
        "# Clear contents if the file exists\n",
        "utils.clear_file(OUTPUT_FILE)\n",
        "\n",
        "\n",
        "## write to the file\n",
        "success = utils.write_tagged_sentences(sents, OUTPUT_FILE)\n",
        "\n",
        "if success:\n",
        "    count = utils.num_found_idioms(OUTPUT_FILE)\n",
        "    print(\"number of idioms found (ish): {}\".format(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "baf9ee51-a641-4086-8e45-38e788a27f8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baf9ee51-a641-4086-8e45-38e788a27f8b",
        "outputId": "a4d6e955-6c49-4748-f532-15a84a5f635f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting script execution: 2022-12-30 19:24:03.756249\n",
            "2022-12-30 19:24:03.756383: Tagged 0 of 238 sentences...\n",
            "Finishing script execution: 2022-12-30 19:24:04.218574\n",
            "number of idioms found (ish): 149\n"
          ]
        }
      ],
      "source": [
        "OUTPUT_FILE = \"./data/tagged_sentences_examples\"\n",
        "\n",
        "examples = list(pd.read_csv(\"./data/idiom_example.csv\")[\"sentence\"])\n",
        "\n",
        "\n",
        "\n",
        "sents = [word_tokenize(sent.replace(\"’\", \"'\").replace(\"–\", \"-\")) \\\n",
        "         for sent in examples]\n",
        "\n",
        "utils.clear_file(OUTPUT_FILE)\n",
        "\n",
        "success = utils.write_tagged_sentences(sents, OUTPUT_FILE)\n",
        "\n",
        "if success:\n",
        "    count = utils.num_found_idioms(OUTPUT_FILE)\n",
        "    print(\"number of idioms found (ish): {}\".format(count))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6ec063a5-ecbf-44a8-8f85-dafaa8733849",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ec063a5-ecbf-44a8-8f85-dafaa8733849",
        "outputId": "71e7e45c-998a-4574-a68d-353962dd96cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting script execution: 2022-12-30 19:24:10.042373\n",
            "2022-12-30 19:24:14.747595: Tagged 0 of 98503 sentences...\n",
            "2022-12-30 19:24:15.824043: Tagged 500 of 98503 sentences...\n",
            "2022-12-30 19:24:16.843433: Tagged 1000 of 98503 sentences...\n",
            "2022-12-30 19:24:17.806989: Tagged 1500 of 98503 sentences...\n",
            "2022-12-30 19:24:18.880950: Tagged 2000 of 98503 sentences...\n",
            "2022-12-30 19:24:19.988660: Tagged 2500 of 98503 sentences...\n",
            "2022-12-30 19:24:21.055011: Tagged 3000 of 98503 sentences...\n",
            "2022-12-30 19:24:22.098247: Tagged 3500 of 98503 sentences...\n",
            "2022-12-30 19:24:23.125481: Tagged 4000 of 98503 sentences...\n",
            "2022-12-30 19:24:24.153049: Tagged 4500 of 98503 sentences...\n",
            "2022-12-30 19:24:26.027471: Tagged 5000 of 98503 sentences...\n",
            "2022-12-30 19:24:28.008905: Tagged 5500 of 98503 sentences...\n",
            "2022-12-30 19:24:29.367856: Tagged 6000 of 98503 sentences...\n",
            "2022-12-30 19:24:30.355395: Tagged 6500 of 98503 sentences...\n",
            "2022-12-30 19:24:31.456263: Tagged 7000 of 98503 sentences...\n",
            "2022-12-30 19:24:32.572971: Tagged 7500 of 98503 sentences...\n",
            "2022-12-30 19:24:33.721589: Tagged 8000 of 98503 sentences...\n",
            "2022-12-30 19:24:34.828176: Tagged 8500 of 98503 sentences...\n",
            "2022-12-30 19:24:35.921758: Tagged 9000 of 98503 sentences...\n",
            "2022-12-30 19:24:36.961479: Tagged 9500 of 98503 sentences...\n",
            "2022-12-30 19:24:38.003989: Tagged 10000 of 98503 sentences...\n",
            "2022-12-30 19:24:38.990329: Tagged 10500 of 98503 sentences...\n",
            "2022-12-30 19:24:40.052054: Tagged 11000 of 98503 sentences...\n",
            "2022-12-30 19:24:41.100776: Tagged 11500 of 98503 sentences...\n",
            "2022-12-30 19:24:42.197026: Tagged 12000 of 98503 sentences...\n",
            "2022-12-30 19:24:43.216164: Tagged 12500 of 98503 sentences...\n",
            "2022-12-30 19:24:44.269472: Tagged 13000 of 98503 sentences...\n",
            "2022-12-30 19:24:45.349043: Tagged 13500 of 98503 sentences...\n",
            "2022-12-30 19:24:46.472222: Tagged 14000 of 98503 sentences...\n",
            "2022-12-30 19:24:47.519507: Tagged 14500 of 98503 sentences...\n",
            "2022-12-30 19:24:48.680304: Tagged 15000 of 98503 sentences...\n",
            "2022-12-30 19:24:49.797669: Tagged 15500 of 98503 sentences...\n",
            "2022-12-30 19:24:50.981286: Tagged 16000 of 98503 sentences...\n",
            "2022-12-30 19:24:52.144848: Tagged 16500 of 98503 sentences...\n",
            "2022-12-30 19:24:53.290470: Tagged 17000 of 98503 sentences...\n",
            "2022-12-30 19:24:54.461803: Tagged 17500 of 98503 sentences...\n",
            "2022-12-30 19:24:55.601348: Tagged 18000 of 98503 sentences...\n",
            "2022-12-30 19:24:56.759622: Tagged 18500 of 98503 sentences...\n",
            "2022-12-30 19:24:57.936911: Tagged 19000 of 98503 sentences...\n",
            "2022-12-30 19:24:59.216954: Tagged 19500 of 98503 sentences...\n",
            "2022-12-30 19:25:00.464978: Tagged 20000 of 98503 sentences...\n",
            "2022-12-30 19:25:01.616404: Tagged 20500 of 98503 sentences...\n",
            "2022-12-30 19:25:02.837934: Tagged 21000 of 98503 sentences...\n",
            "2022-12-30 19:25:04.090327: Tagged 21500 of 98503 sentences...\n",
            "2022-12-30 19:25:05.385073: Tagged 22000 of 98503 sentences...\n",
            "2022-12-30 19:25:06.499076: Tagged 22500 of 98503 sentences...\n",
            "2022-12-30 19:25:07.618770: Tagged 23000 of 98503 sentences...\n",
            "2022-12-30 19:25:08.726002: Tagged 23500 of 98503 sentences...\n",
            "2022-12-30 19:25:09.861262: Tagged 24000 of 98503 sentences...\n",
            "2022-12-30 19:25:10.970810: Tagged 24500 of 98503 sentences...\n",
            "2022-12-30 19:25:12.174881: Tagged 25000 of 98503 sentences...\n",
            "2022-12-30 19:25:13.283328: Tagged 25500 of 98503 sentences...\n",
            "2022-12-30 19:25:14.362126: Tagged 26000 of 98503 sentences...\n",
            "2022-12-30 19:25:15.545291: Tagged 26500 of 98503 sentences...\n",
            "2022-12-30 19:25:16.702940: Tagged 27000 of 98503 sentences...\n",
            "2022-12-30 19:25:17.909055: Tagged 27500 of 98503 sentences...\n",
            "2022-12-30 19:25:19.116174: Tagged 28000 of 98503 sentences...\n",
            "2022-12-30 19:25:20.304487: Tagged 28500 of 98503 sentences...\n",
            "2022-12-30 19:25:21.387255: Tagged 29000 of 98503 sentences...\n",
            "2022-12-30 19:25:22.377401: Tagged 29500 of 98503 sentences...\n",
            "2022-12-30 19:25:23.377149: Tagged 30000 of 98503 sentences...\n",
            "2022-12-30 19:25:24.396885: Tagged 30500 of 98503 sentences...\n",
            "2022-12-30 19:25:25.378542: Tagged 31000 of 98503 sentences...\n",
            "2022-12-30 19:25:26.358276: Tagged 31500 of 98503 sentences...\n",
            "2022-12-30 19:25:27.349824: Tagged 32000 of 98503 sentences...\n",
            "2022-12-30 19:25:28.332847: Tagged 32500 of 98503 sentences...\n",
            "2022-12-30 19:25:29.347729: Tagged 33000 of 98503 sentences...\n",
            "2022-12-30 19:25:30.407979: Tagged 33500 of 98503 sentences...\n",
            "2022-12-30 19:25:31.525527: Tagged 34000 of 98503 sentences...\n",
            "2022-12-30 19:25:32.665262: Tagged 34500 of 98503 sentences...\n",
            "2022-12-30 19:25:33.815977: Tagged 35000 of 98503 sentences...\n",
            "2022-12-30 19:25:34.958338: Tagged 35500 of 98503 sentences...\n",
            "2022-12-30 19:25:36.237353: Tagged 36000 of 98503 sentences...\n",
            "2022-12-30 19:25:37.358461: Tagged 36500 of 98503 sentences...\n",
            "2022-12-30 19:25:38.563361: Tagged 37000 of 98503 sentences...\n",
            "2022-12-30 19:25:39.824959: Tagged 37500 of 98503 sentences...\n",
            "2022-12-30 19:25:41.009378: Tagged 38000 of 98503 sentences...\n",
            "2022-12-30 19:25:42.122096: Tagged 38500 of 98503 sentences...\n",
            "2022-12-30 19:25:43.222257: Tagged 39000 of 98503 sentences...\n",
            "2022-12-30 19:25:44.313335: Tagged 39500 of 98503 sentences...\n",
            "2022-12-30 19:25:45.366628: Tagged 40000 of 98503 sentences...\n",
            "2022-12-30 19:25:46.435921: Tagged 40500 of 98503 sentences...\n",
            "2022-12-30 19:25:47.533299: Tagged 41000 of 98503 sentences...\n",
            "2022-12-30 19:25:48.633019: Tagged 41500 of 98503 sentences...\n",
            "2022-12-30 19:25:49.693435: Tagged 42000 of 98503 sentences...\n",
            "2022-12-30 19:25:50.708550: Tagged 42500 of 98503 sentences...\n",
            "2022-12-30 19:25:51.779551: Tagged 43000 of 98503 sentences...\n",
            "2022-12-30 19:25:52.835325: Tagged 43500 of 98503 sentences...\n",
            "2022-12-30 19:25:53.929745: Tagged 44000 of 98503 sentences...\n",
            "2022-12-30 19:25:55.005931: Tagged 44500 of 98503 sentences...\n",
            "2022-12-30 19:25:56.113459: Tagged 45000 of 98503 sentences...\n",
            "2022-12-30 19:25:57.321905: Tagged 45500 of 98503 sentences...\n",
            "2022-12-30 19:25:58.445829: Tagged 46000 of 98503 sentences...\n",
            "2022-12-30 19:25:59.585881: Tagged 46500 of 98503 sentences...\n",
            "2022-12-30 19:26:00.544394: Tagged 47000 of 98503 sentences...\n",
            "2022-12-30 19:26:01.472058: Tagged 47500 of 98503 sentences...\n",
            "2022-12-30 19:26:02.436624: Tagged 48000 of 98503 sentences...\n",
            "2022-12-30 19:26:03.386848: Tagged 48500 of 98503 sentences...\n",
            "2022-12-30 19:26:04.348281: Tagged 49000 of 98503 sentences...\n",
            "2022-12-30 19:26:05.334733: Tagged 49500 of 98503 sentences...\n",
            "2022-12-30 19:26:06.283724: Tagged 50000 of 98503 sentences...\n",
            "2022-12-30 19:26:07.203689: Tagged 50500 of 98503 sentences...\n",
            "2022-12-30 19:26:08.141662: Tagged 51000 of 98503 sentences...\n",
            "2022-12-30 19:26:09.075570: Tagged 51500 of 98503 sentences...\n",
            "2022-12-30 19:26:10.000615: Tagged 52000 of 98503 sentences...\n",
            "2022-12-30 19:26:10.907396: Tagged 52500 of 98503 sentences...\n",
            "2022-12-30 19:26:11.875955: Tagged 53000 of 98503 sentences...\n",
            "2022-12-30 19:26:12.832309: Tagged 53500 of 98503 sentences...\n",
            "2022-12-30 19:26:13.750475: Tagged 54000 of 98503 sentences...\n",
            "2022-12-30 19:26:14.691140: Tagged 54500 of 98503 sentences...\n",
            "2022-12-30 19:26:15.722504: Tagged 55000 of 98503 sentences...\n",
            "2022-12-30 19:26:16.759731: Tagged 55500 of 98503 sentences...\n",
            "2022-12-30 19:26:17.742301: Tagged 56000 of 98503 sentences...\n",
            "2022-12-30 19:26:18.726939: Tagged 56500 of 98503 sentences...\n",
            "2022-12-30 19:26:19.707323: Tagged 57000 of 98503 sentences...\n",
            "2022-12-30 19:26:20.723488: Tagged 57500 of 98503 sentences...\n",
            "2022-12-30 19:26:21.719260: Tagged 58000 of 98503 sentences...\n",
            "2022-12-30 19:26:22.694344: Tagged 58500 of 98503 sentences...\n",
            "2022-12-30 19:26:23.706537: Tagged 59000 of 98503 sentences...\n",
            "2022-12-30 19:26:24.766217: Tagged 59500 of 98503 sentences...\n",
            "2022-12-30 19:26:25.816809: Tagged 60000 of 98503 sentences...\n",
            "2022-12-30 19:26:26.805703: Tagged 60500 of 98503 sentences...\n",
            "2022-12-30 19:26:27.791008: Tagged 61000 of 98503 sentences...\n",
            "2022-12-30 19:26:28.757027: Tagged 61500 of 98503 sentences...\n",
            "2022-12-30 19:26:29.713190: Tagged 62000 of 98503 sentences...\n",
            "2022-12-30 19:26:30.678761: Tagged 62500 of 98503 sentences...\n",
            "2022-12-30 19:26:31.628732: Tagged 63000 of 98503 sentences...\n",
            "2022-12-30 19:26:32.593292: Tagged 63500 of 98503 sentences...\n",
            "2022-12-30 19:26:33.562834: Tagged 64000 of 98503 sentences...\n",
            "2022-12-30 19:26:34.502714: Tagged 64500 of 98503 sentences...\n",
            "2022-12-30 19:26:35.488224: Tagged 65000 of 98503 sentences...\n",
            "2022-12-30 19:26:36.522647: Tagged 65500 of 98503 sentences...\n",
            "2022-12-30 19:26:37.520697: Tagged 66000 of 98503 sentences...\n",
            "2022-12-30 19:26:38.560851: Tagged 66500 of 98503 sentences...\n",
            "2022-12-30 19:26:39.584525: Tagged 67000 of 98503 sentences...\n",
            "2022-12-30 19:26:40.631329: Tagged 67500 of 98503 sentences...\n",
            "2022-12-30 19:26:41.665732: Tagged 68000 of 98503 sentences...\n",
            "2022-12-30 19:26:42.550121: Tagged 68500 of 98503 sentences...\n",
            "2022-12-30 19:26:43.389856: Tagged 69000 of 98503 sentences...\n",
            "2022-12-30 19:26:44.247987: Tagged 69500 of 98503 sentences...\n",
            "2022-12-30 19:26:45.266879: Tagged 70000 of 98503 sentences...\n",
            "2022-12-30 19:26:46.319156: Tagged 70500 of 98503 sentences...\n",
            "2022-12-30 19:26:47.145001: Tagged 71000 of 98503 sentences...\n",
            "2022-12-30 19:26:48.189967: Tagged 71500 of 98503 sentences...\n",
            "2022-12-30 19:26:49.201624: Tagged 72000 of 98503 sentences...\n",
            "2022-12-30 19:26:51.041376: Tagged 72500 of 98503 sentences...\n",
            "2022-12-30 19:26:52.863819: Tagged 73000 of 98503 sentences...\n",
            "2022-12-30 19:26:54.100606: Tagged 73500 of 98503 sentences...\n",
            "2022-12-30 19:26:55.158291: Tagged 74000 of 98503 sentences...\n",
            "2022-12-30 19:26:56.157639: Tagged 74500 of 98503 sentences...\n",
            "2022-12-30 19:26:57.127566: Tagged 75000 of 98503 sentences...\n",
            "2022-12-30 19:26:58.080929: Tagged 75500 of 98503 sentences...\n",
            "2022-12-30 19:26:59.142641: Tagged 76000 of 98503 sentences...\n",
            "2022-12-30 19:27:00.208897: Tagged 76500 of 98503 sentences...\n",
            "2022-12-30 19:27:01.244336: Tagged 77000 of 98503 sentences...\n",
            "2022-12-30 19:27:02.246380: Tagged 77500 of 98503 sentences...\n",
            "2022-12-30 19:27:03.202175: Tagged 78000 of 98503 sentences...\n",
            "2022-12-30 19:27:04.192703: Tagged 78500 of 98503 sentences...\n",
            "2022-12-30 19:27:05.194277: Tagged 79000 of 98503 sentences...\n",
            "2022-12-30 19:27:06.259308: Tagged 79500 of 98503 sentences...\n",
            "2022-12-30 19:27:07.336552: Tagged 80000 of 98503 sentences...\n",
            "2022-12-30 19:27:08.438508: Tagged 80500 of 98503 sentences...\n",
            "2022-12-30 19:27:09.465767: Tagged 81000 of 98503 sentences...\n",
            "2022-12-30 19:27:10.559566: Tagged 81500 of 98503 sentences...\n",
            "2022-12-30 19:27:11.706024: Tagged 82000 of 98503 sentences...\n",
            "2022-12-30 19:27:12.742242: Tagged 82500 of 98503 sentences...\n",
            "2022-12-30 19:27:13.738729: Tagged 83000 of 98503 sentences...\n",
            "2022-12-30 19:27:14.783395: Tagged 83500 of 98503 sentences...\n",
            "2022-12-30 19:27:15.789480: Tagged 84000 of 98503 sentences...\n",
            "2022-12-30 19:27:16.756417: Tagged 84500 of 98503 sentences...\n",
            "2022-12-30 19:27:17.748522: Tagged 85000 of 98503 sentences...\n",
            "2022-12-30 19:27:18.882690: Tagged 85500 of 98503 sentences...\n",
            "2022-12-30 19:27:20.241709: Tagged 86000 of 98503 sentences...\n",
            "2022-12-30 19:27:21.573485: Tagged 86500 of 98503 sentences...\n",
            "2022-12-30 19:27:22.820143: Tagged 87000 of 98503 sentences...\n",
            "2022-12-30 19:27:23.819060: Tagged 87500 of 98503 sentences...\n",
            "2022-12-30 19:27:24.722819: Tagged 88000 of 98503 sentences...\n",
            "2022-12-30 19:27:25.621528: Tagged 88500 of 98503 sentences...\n",
            "2022-12-30 19:27:26.446545: Tagged 89000 of 98503 sentences...\n",
            "2022-12-30 19:27:27.299023: Tagged 89500 of 98503 sentences...\n",
            "2022-12-30 19:27:28.160972: Tagged 90000 of 98503 sentences...\n",
            "2022-12-30 19:27:29.045746: Tagged 90500 of 98503 sentences...\n",
            "2022-12-30 19:27:29.891054: Tagged 91000 of 98503 sentences...\n",
            "2022-12-30 19:27:30.727838: Tagged 91500 of 98503 sentences...\n",
            "2022-12-30 19:27:31.575037: Tagged 92000 of 98503 sentences...\n",
            "2022-12-30 19:27:32.393924: Tagged 92500 of 98503 sentences...\n",
            "2022-12-30 19:27:33.239124: Tagged 93000 of 98503 sentences...\n",
            "2022-12-30 19:27:34.083159: Tagged 93500 of 98503 sentences...\n",
            "2022-12-30 19:27:34.915058: Tagged 94000 of 98503 sentences...\n",
            "2022-12-30 19:27:35.866524: Tagged 94500 of 98503 sentences...\n",
            "2022-12-30 19:27:36.992366: Tagged 95000 of 98503 sentences...\n",
            "2022-12-30 19:27:38.137377: Tagged 95500 of 98503 sentences...\n",
            "2022-12-30 19:27:39.287780: Tagged 96000 of 98503 sentences...\n",
            "2022-12-30 19:27:40.305470: Tagged 96500 of 98503 sentences...\n",
            "2022-12-30 19:27:41.447564: Tagged 97000 of 98503 sentences...\n",
            "2022-12-30 19:27:42.571919: Tagged 97500 of 98503 sentences...\n",
            "2022-12-30 19:27:43.656626: Tagged 98000 of 98503 sentences...\n",
            "2022-12-30 19:27:44.754523: Tagged 98500 of 98503 sentences...\n",
            "Finishing script execution: 2022-12-30 19:27:44.762359\n",
            "number of idioms found (ish): 717\n"
          ]
        }
      ],
      "source": [
        "# gutenberg\n",
        "OUTPUT_FILE = \"./data/tagged_sentences_gutenberg\"\n",
        "\n",
        "# Clear contents if the file exists\n",
        "utils.clear_file(OUTPUT_FILE)\n",
        "\n",
        "## write to the file\n",
        "success = utils.write_tagged_sentences(gutenberg.sents(), OUTPUT_FILE)\n",
        "\n",
        "if success:\n",
        "    count = utils.num_found_idioms(OUTPUT_FILE)\n",
        "    print(\"number of idioms found (ish): {}\".format(count))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "008d5e52-9d63-49a8-a815-8e3ad5cb9a9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "008d5e52-9d63-49a8-a815-8e3ad5cb9a9a",
        "outputId": "492348e7-585e-4dfe-bbca-5c8969a720bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting script execution: 2022-12-30 19:30:12.031240\n",
            "2022-12-30 19:30:16.955812: Tagged 0 of 54711 sentences...\n",
            "2022-12-30 19:30:18.103938: Tagged 500 of 54711 sentences...\n",
            "2022-12-30 19:30:19.244926: Tagged 1000 of 54711 sentences...\n",
            "2022-12-30 19:30:20.428264: Tagged 1500 of 54711 sentences...\n",
            "2022-12-30 19:30:21.531753: Tagged 2000 of 54711 sentences...\n",
            "2022-12-30 19:30:22.675479: Tagged 2500 of 54711 sentences...\n",
            "2022-12-30 19:30:23.812592: Tagged 3000 of 54711 sentences...\n",
            "2022-12-30 19:30:24.975010: Tagged 3500 of 54711 sentences...\n",
            "2022-12-30 19:30:26.129284: Tagged 4000 of 54711 sentences...\n",
            "2022-12-30 19:30:27.258519: Tagged 4500 of 54711 sentences...\n",
            "2022-12-30 19:30:28.370834: Tagged 5000 of 54711 sentences...\n",
            "2022-12-30 19:30:29.456172: Tagged 5500 of 54711 sentences...\n",
            "2022-12-30 19:30:30.598095: Tagged 6000 of 54711 sentences...\n",
            "2022-12-30 19:30:31.688999: Tagged 6500 of 54711 sentences...\n",
            "2022-12-30 19:30:32.804026: Tagged 7000 of 54711 sentences...\n",
            "2022-12-30 19:30:33.883484: Tagged 7500 of 54711 sentences...\n",
            "2022-12-30 19:30:35.016981: Tagged 8000 of 54711 sentences...\n",
            "2022-12-30 19:30:36.144304: Tagged 8500 of 54711 sentences...\n",
            "2022-12-30 19:30:37.256284: Tagged 9000 of 54711 sentences...\n",
            "2022-12-30 19:30:38.363838: Tagged 9500 of 54711 sentences...\n",
            "2022-12-30 19:30:39.474305: Tagged 10000 of 54711 sentences...\n",
            "2022-12-30 19:30:40.636245: Tagged 10500 of 54711 sentences...\n",
            "2022-12-30 19:30:41.788385: Tagged 11000 of 54711 sentences...\n",
            "2022-12-30 19:30:42.912525: Tagged 11500 of 54711 sentences...\n",
            "2022-12-30 19:30:44.071062: Tagged 12000 of 54711 sentences...\n",
            "2022-12-30 19:30:45.281290: Tagged 12500 of 54711 sentences...\n",
            "2022-12-30 19:30:46.465382: Tagged 13000 of 54711 sentences...\n",
            "2022-12-30 19:30:47.582517: Tagged 13500 of 54711 sentences...\n",
            "2022-12-30 19:30:48.801890: Tagged 14000 of 54711 sentences...\n",
            "2022-12-30 19:30:49.944956: Tagged 14500 of 54711 sentences...\n",
            "2022-12-30 19:30:51.070313: Tagged 15000 of 54711 sentences...\n",
            "2022-12-30 19:30:52.164972: Tagged 15500 of 54711 sentences...\n",
            "2022-12-30 19:30:53.255045: Tagged 16000 of 54711 sentences...\n",
            "2022-12-30 19:30:54.388317: Tagged 16500 of 54711 sentences...\n",
            "2022-12-30 19:30:55.488055: Tagged 17000 of 54711 sentences...\n",
            "2022-12-30 19:30:56.598827: Tagged 17500 of 54711 sentences...\n",
            "2022-12-30 19:30:57.738534: Tagged 18000 of 54711 sentences...\n",
            "2022-12-30 19:30:58.846866: Tagged 18500 of 54711 sentences...\n",
            "2022-12-30 19:30:59.943363: Tagged 19000 of 54711 sentences...\n",
            "2022-12-30 19:31:01.102759: Tagged 19500 of 54711 sentences...\n",
            "2022-12-30 19:31:02.221415: Tagged 20000 of 54711 sentences...\n",
            "2022-12-30 19:31:03.333528: Tagged 20500 of 54711 sentences...\n",
            "2022-12-30 19:31:04.442826: Tagged 21000 of 54711 sentences...\n",
            "2022-12-30 19:31:05.590868: Tagged 21500 of 54711 sentences...\n",
            "2022-12-30 19:31:06.693632: Tagged 22000 of 54711 sentences...\n",
            "2022-12-30 19:31:07.826065: Tagged 22500 of 54711 sentences...\n",
            "2022-12-30 19:31:08.956665: Tagged 23000 of 54711 sentences...\n",
            "2022-12-30 19:31:10.077012: Tagged 23500 of 54711 sentences...\n",
            "2022-12-30 19:31:11.178173: Tagged 24000 of 54711 sentences...\n",
            "2022-12-30 19:31:12.282490: Tagged 24500 of 54711 sentences...\n",
            "2022-12-30 19:31:13.399570: Tagged 25000 of 54711 sentences...\n",
            "2022-12-30 19:31:14.510967: Tagged 25500 of 54711 sentences...\n",
            "2022-12-30 19:31:15.674857: Tagged 26000 of 54711 sentences...\n",
            "2022-12-30 19:31:16.811245: Tagged 26500 of 54711 sentences...\n",
            "2022-12-30 19:31:17.952479: Tagged 27000 of 54711 sentences...\n",
            "2022-12-30 19:31:19.075301: Tagged 27500 of 54711 sentences...\n",
            "2022-12-30 19:31:20.224230: Tagged 28000 of 54711 sentences...\n",
            "2022-12-30 19:31:21.383044: Tagged 28500 of 54711 sentences...\n",
            "2022-12-30 19:31:22.506820: Tagged 29000 of 54711 sentences...\n",
            "2022-12-30 19:31:23.634128: Tagged 29500 of 54711 sentences...\n",
            "2022-12-30 19:31:24.781045: Tagged 30000 of 54711 sentences...\n",
            "2022-12-30 19:31:25.933029: Tagged 30500 of 54711 sentences...\n",
            "2022-12-30 19:31:27.071400: Tagged 31000 of 54711 sentences...\n",
            "2022-12-30 19:31:28.193083: Tagged 31500 of 54711 sentences...\n",
            "2022-12-30 19:31:29.332201: Tagged 32000 of 54711 sentences...\n",
            "2022-12-30 19:31:30.497373: Tagged 32500 of 54711 sentences...\n",
            "2022-12-30 19:31:31.622977: Tagged 33000 of 54711 sentences...\n",
            "2022-12-30 19:31:32.789245: Tagged 33500 of 54711 sentences...\n",
            "2022-12-30 19:31:33.932346: Tagged 34000 of 54711 sentences...\n",
            "2022-12-30 19:31:35.093313: Tagged 34500 of 54711 sentences...\n",
            "2022-12-30 19:31:36.193320: Tagged 35000 of 54711 sentences...\n",
            "2022-12-30 19:31:37.280003: Tagged 35500 of 54711 sentences...\n",
            "2022-12-30 19:31:38.679565: Tagged 36000 of 54711 sentences...\n",
            "2022-12-30 19:31:40.793588: Tagged 36500 of 54711 sentences...\n",
            "2022-12-30 19:31:42.805573: Tagged 37000 of 54711 sentences...\n",
            "2022-12-30 19:31:43.926130: Tagged 37500 of 54711 sentences...\n",
            "2022-12-30 19:31:45.053267: Tagged 38000 of 54711 sentences...\n",
            "2022-12-30 19:31:46.163710: Tagged 38500 of 54711 sentences...\n",
            "2022-12-30 19:31:47.248890: Tagged 39000 of 54711 sentences...\n",
            "2022-12-30 19:31:48.403360: Tagged 39500 of 54711 sentences...\n",
            "2022-12-30 19:31:49.546563: Tagged 40000 of 54711 sentences...\n",
            "2022-12-30 19:31:50.703367: Tagged 40500 of 54711 sentences...\n",
            "2022-12-30 19:31:51.843747: Tagged 41000 of 54711 sentences...\n",
            "2022-12-30 19:31:52.939988: Tagged 41500 of 54711 sentences...\n",
            "2022-12-30 19:31:54.062584: Tagged 42000 of 54711 sentences...\n",
            "2022-12-30 19:31:55.222037: Tagged 42500 of 54711 sentences...\n",
            "2022-12-30 19:31:56.324503: Tagged 43000 of 54711 sentences...\n",
            "2022-12-30 19:31:57.483732: Tagged 43500 of 54711 sentences...\n",
            "2022-12-30 19:31:58.624398: Tagged 44000 of 54711 sentences...\n",
            "2022-12-30 19:31:59.784097: Tagged 44500 of 54711 sentences...\n",
            "2022-12-30 19:32:00.948644: Tagged 45000 of 54711 sentences...\n",
            "2022-12-30 19:32:02.087385: Tagged 45500 of 54711 sentences...\n",
            "2022-12-30 19:32:03.236223: Tagged 46000 of 54711 sentences...\n",
            "2022-12-30 19:32:04.383364: Tagged 46500 of 54711 sentences...\n",
            "2022-12-30 19:32:05.549279: Tagged 47000 of 54711 sentences...\n",
            "2022-12-30 19:32:06.765156: Tagged 47500 of 54711 sentences...\n",
            "2022-12-30 19:32:07.898517: Tagged 48000 of 54711 sentences...\n",
            "2022-12-30 19:32:09.029530: Tagged 48500 of 54711 sentences...\n",
            "2022-12-30 19:32:10.222289: Tagged 49000 of 54711 sentences...\n",
            "2022-12-30 19:32:11.368700: Tagged 49500 of 54711 sentences...\n",
            "2022-12-30 19:32:12.820227: Tagged 50000 of 54711 sentences...\n",
            "2022-12-30 19:32:13.928948: Tagged 50500 of 54711 sentences...\n",
            "2022-12-30 19:32:15.034836: Tagged 51000 of 54711 sentences...\n",
            "2022-12-30 19:32:16.128955: Tagged 51500 of 54711 sentences...\n",
            "2022-12-30 19:32:17.208864: Tagged 52000 of 54711 sentences...\n",
            "2022-12-30 19:32:18.321122: Tagged 52500 of 54711 sentences...\n",
            "2022-12-30 19:32:19.480868: Tagged 53000 of 54711 sentences...\n",
            "2022-12-30 19:32:20.608090: Tagged 53500 of 54711 sentences...\n",
            "2022-12-30 19:32:21.686821: Tagged 54000 of 54711 sentences...\n",
            "2022-12-30 19:32:22.804365: Tagged 54500 of 54711 sentences...\n",
            "Finishing script execution: 2022-12-30 19:32:23.286182\n",
            "number of idioms found (ish): 216\n"
          ]
        }
      ],
      "source": [
        "# reuters\n",
        "OUTPUT_FILE = \"./data/tagged_sentences_reuters\"\n",
        "\n",
        "sents = reuters.sents()\n",
        "\n",
        "# Clear contents if the file exists\n",
        "utils.clear_file(OUTPUT_FILE)\n",
        "\n",
        "\n",
        "## write to the file\n",
        "success = utils.write_tagged_sentences(reuters.sents(), OUTPUT_FILE)\n",
        "\n",
        "if success:\n",
        "    count = utils.num_found_idioms(OUTPUT_FILE)\n",
        "    print(\"number of idioms found (ish): {}\".format(count))\n",
        "\n",
        "\n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "493e6c03-0ea8-4b08-ab10-1474f76143f0",
      "metadata": {
        "id": "493e6c03-0ea8-4b08-ab10-1474f76143f0"
      },
      "source": [
        "## Preparing to Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f2f8cc0b-e944-428f-9fdf-ded2af3f414b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2f8cc0b-e944-428f-9fdf-ded2af3f414b",
        "outputId": "6de9d2af-0ebf-4d0f-8384-9b000f56a72d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-30 19:32:40.772945: Gathering all the words...\n",
            "2022-12-30 19:32:41.011085: Lowercasing all the words...\n",
            "2022-12-30 19:33:09.316613: Lemmatizing all the words...\n",
            "2022-12-30 19:37:38.878156: Creating bigrams frequencies and storing results...\n",
            "2022-12-30 19:40:31.871417: Creating unigrams frequencies and storing results...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "OUT_PATH = \"./data/{}.pkl\"\n",
        "\n",
        "print(\"{}: Gathering all the words...\".format(datetime.now()))\n",
        "\n",
        "idiom_examples = pd.read_csv(\"./data/idiom_example.csv\")[\"sentence\"]\n",
        "\n",
        "idiom_examples_split = [nltk.word_tokenize(sent) for sent in idiom_examples]\n",
        "\n",
        "examples_words = [word for sent in idiom_examples_split \\\n",
        "                  for word in sent]\n",
        "\n",
        "# this doesn't work, a little salty about it\n",
        "#examples_words = [word for word_tokenize(sent) in idiom_examples \\\n",
        "#                  for word in word_tokenize(sent)]\n",
        "\n",
        "# Does it matter that the last sentence of one document will be combined with \n",
        "# the first sentence of another?\n",
        "words = brown.words() + gutenberg.words() + reuters.words() + examples_words\n",
        "\n",
        "print(\"{}: Lowercasing all the words...\".format(datetime.now()))\n",
        "words_lower = [w.lower() for w in words]\n",
        "\n",
        "print(\"{}: Lemmatizing all the words...\".format(datetime.now()))\n",
        "wnlt = nltk.WordNetLemmatizer()\n",
        "words_lemmatized = [wnlt.lemmatize(word, utils.get_wordnet_pos(tb_pos)) \\\n",
        "         for word,tb_pos in nltk.pos_tag(words_lower)]\n",
        "\n",
        "#bigrams = nltk.collocations.BigramCollocationFinder.from_words(\n",
        "#        words,\n",
        "#        window_size=20)\n",
        "\n",
        "#bigrams.apply_freq_filter(20)\n",
        "#bigrams_freq = bigrams.ngram_fd\n",
        "\n",
        "\n",
        "### TODO(?) : Try different windowsizes\n",
        "print(\"{}: Creating bigrams frequencies and storing results...\".format(datetime.now()))\n",
        "bigrams_freq = BigramCollocationFinder.from_words(words_lemmatized, window_size=20).ngram_fd\n",
        "\n",
        "with open(OUT_PATH.format(\"bigram_freq\"), \"wb\") as f:\n",
        "    pickle.dump(bigrams_freq, f)\n",
        "\n",
        "\n",
        "print(\"{}: Creating unigrams frequencies and storing results...\".format(datetime.now()))\n",
        "unigrams = nltk.FreqDist(words_lemmatized)\n",
        "unigrams_freq = nltk.FreqDist(words_lemmatized)\n",
        "#unigrams_freq = {unigram:freq for unigram, freq in unigrams.items() if freq >= 20}\n",
        "\n",
        "with open(OUT_PATH.format(\"unigrams_freq\"), \"wb\") as f:\n",
        "    pickle.dump(unigrams_freq, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b1a3e69f-3059-4d88-bad2-293193cb68c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1a3e69f-3059-4d88-bad2-293193cb68c2",
        "outputId": "f8fb9f1b-b56f-4f2d-adff-4077cc0730f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-30 19:40:51.757950: Reading tagged sentences...\n",
            "2022-12-30 19:40:51.762848: Tagging sentences from ./data/tagged_sentences_brown...\n",
            "2022-12-30 19:41:51.720388: Finished!\n",
            "2022-12-30 19:41:51.720560: Adding newly tagged sentences to rest of sentences...\n",
            "2022-12-30 19:41:51.722739: Finished!\n",
            "2022-12-30 19:41:51.725197: Tagging sentences from ./data/tagged_sentences_reuters...\n",
            "2022-12-30 19:43:10.780896: Finished!\n",
            "2022-12-30 19:43:10.781059: Adding newly tagged sentences to rest of sentences...\n",
            "2022-12-30 19:43:10.784361: Finished!\n",
            "2022-12-30 19:43:10.785395: Tagging sentences from ./data/tagged_sentences_gutenberg...\n",
            "2022-12-30 19:45:12.409925: Finished!\n",
            "2022-12-30 19:45:12.410120: Adding newly tagged sentences to rest of sentences...\n",
            "2022-12-30 19:45:12.413798: Finished!\n",
            "2022-12-30 19:45:12.414081: Tagging sentences from ./data/tagged_sentences_examples...\n",
            "2022-12-30 19:45:12.616085: Finished!\n",
            "2022-12-30 19:45:12.616840: Adding newly tagged sentences to rest of sentences...\n",
            "2022-12-30 19:45:12.616907: Finished!\n",
            "2022-12-30 19:45:12.619009: Creating train and test datasets...\n",
            "2022-12-30 19:45:13.604276: Writing train data to file via pickle ...\n",
            "2022-12-30 19:45:13.695088: Writing test data to file via pickle ...\n",
            "2022-12-30 19:45:13.712167: Finished!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "INPUT = [\"./data/tagged_sentences_brown\",\n",
        "         \"./data/tagged_sentences_reuters\",\n",
        "         \"./data/tagged_sentences_gutenberg\",\n",
        "         \"./data/tagged_sentences_examples\"]\n",
        "\n",
        "TRAIN_PCT = 0.8\n",
        "UNDERSAMPLE_FACTOR = 4\n",
        "OUT_PATH = \"./data/{}.pkl\"\n",
        "SEED = 20190619\n",
        "\n",
        "\n",
        "print(\"{}: Reading tagged sentences...\".format(datetime.now()))\n",
        "tagged_sentences = []\n",
        "for fname in INPUT:\n",
        "    with open(fname, \"r\") as f: \n",
        "        print(\"{}: Tagging sentences from {}...\".format(datetime.now(), fname))\n",
        "        ts = [utils.tag_line(line) for line in f]\n",
        "        print(\"{}: Finished!\".format(datetime.now()))\n",
        "       \n",
        "        print(\"{}: Adding newly tagged sentences to rest of sentences...\"\n",
        "                      .format(datetime.now()))\n",
        "        tagged_sentences.extend(ts)\n",
        "        print(\"{}: Finished!\".format(datetime.now()))\n",
        "        \n",
        "\n",
        "print(\"{}: Creating train and test datasets...\".format(datetime.now()))\n",
        "\n",
        "train, test = utils.stratified_train_test(tagged_sentences,\n",
        "                                    SEED,\n",
        "                                    TRAIN_PCT,\n",
        "                                    UNDERSAMPLE_FACTOR)\n",
        "\n",
        "print(\"{}: Writing train data to file via pickle ...\".format(datetime.now()))\n",
        "\n",
        "with open(OUT_PATH.format(\"train\"), \"wb\") as f:\n",
        "    pickle.dump(train, f)\n",
        "\n",
        "print(\"{}: Writing test data to file via pickle ...\".format(datetime.now()))\n",
        "\n",
        "with open(OUT_PATH.format(\"test\"), \"wb\") as f:\n",
        "    pickle.dump(test, f)\n",
        "\n",
        "print(\"{}: Finished!\".format(datetime.now()))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79433f27-c1a3-4dcd-b06c-2ff5c277c2cf",
      "metadata": {
        "id": "79433f27-c1a3-4dcd-b06c-2ff5c277c2cf"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d0de33b7-8d2a-4028-be83-49459874a4eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0de33b7-8d2a-4028-be83-49459874a4eb",
        "outputId": "9225419f-b0fd-45ba-ec3a-a2cee9b0bcf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('12', 'CD', 'OUT'),\n",
              " (':', ':', 'OUT'),\n",
              " ('41', 'CD', 'OUT'),\n",
              " ('The', 'DT', 'OUT'),\n",
              " ('men', 'NNS', 'OUT'),\n",
              " ('of', 'IN', 'OUT'),\n",
              " ('Nineveh', 'NNP', 'OUT'),\n",
              " ('shall', 'MD', 'OUT'),\n",
              " ('rise', 'VB', 'OUT'),\n",
              " ('in', 'IN', 'OUT'),\n",
              " ('judgment', 'NN', 'OUT'),\n",
              " ('with', 'IN', 'OUT'),\n",
              " ('this', 'DT', 'OUT'),\n",
              " ('generation', 'NN', 'OUT'),\n",
              " (',', ',', 'OUT'),\n",
              " ('and', 'CC', 'OUT'),\n",
              " ('shall', 'MD', 'OUT'),\n",
              " ('condemn', 'VB', 'OUT'),\n",
              " ('it', 'PRP', 'OUT'),\n",
              " (':', ':', 'OUT'),\n",
              " ('because', 'IN', 'OUT'),\n",
              " ('they', 'PRP', 'OUT'),\n",
              " ('repented', 'VBD', 'OUT'),\n",
              " ('at', 'IN', 'OUT'),\n",
              " ('the', 'DT', 'OUT'),\n",
              " ('preaching', 'NN', 'OUT'),\n",
              " ('of', 'IN', 'OUT'),\n",
              " ('Jonas', 'NNP', 'OUT'),\n",
              " (';', ':', 'OUT'),\n",
              " ('and', 'CC', 'OUT'),\n",
              " (',', ',', 'OUT'),\n",
              " ('behold', 'RB', 'OUT'),\n",
              " (',', ',', 'OUT'),\n",
              " ('a', 'DT', 'OUT'),\n",
              " ('greater', 'JJR', 'OUT'),\n",
              " ('than', 'IN', 'OUT'),\n",
              " ('Jonas', 'NNP', 'OUT'),\n",
              " ('is', 'VBZ', 'OUT'),\n",
              " ('here', 'RB', 'OUT'),\n",
              " ('.', '.', 'OUT')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1967fb86-cb13-4f74-9261-c3a52520ac36",
      "metadata": {
        "id": "1967fb86-cb13-4f74-9261-c3a52520ac36"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"./data/{}.pkl\"\n",
        "\n",
        "with open(DATA_PATH.format(\"train\"), \"rb\") as f:\n",
        "    train = pickle.load(f)\n",
        "    \n",
        "with open(DATA_PATH.format(\"test\"), \"rb\") as f:\n",
        "    test = pickle.load(f)\n",
        "\n",
        "train[0][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b49d0c0a-964d-471c-ab0a-26f522d31aba",
      "metadata": {
        "id": "b49d0c0a-964d-471c-ab0a-26f522d31aba"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(WORD2VEC_FILE):\n",
        "    WORD2VEC = word2vec.KeyedVectors.load_word2vec_format(\n",
        "        WORD2VEC_FILE,\n",
        "        binary=True)\n",
        "else:\n",
        "    print(\"Pretrain Word2Vec model not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "053f7c2d-6cf4-4ef7-a529-5b4ddbbd59f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "053f7c2d-6cf4-4ef7-a529-5b4ddbbd59f1",
        "outputId": "8ec862bd-3383-4f1a-f70e-94f61000a25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-30 19:54:15.093718: Creating features for train set...\n",
            "2022-12-30 19:54:50.423860: Getting labels for train set...\n",
            "2022-12-30 19:54:50.455191: Creating features for test set\n",
            "2022-12-30 19:54:56.761118: Getting labels for test set...\n",
            "2022-12-30 19:54:56.771370: Finished!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bias': 1.0,\n",
              " 'word.lower()': '12',\n",
              " 'word[-3:]': '12',\n",
              " 'word.isupper()': False,\n",
              " 'word.istitle()': False,\n",
              " 'word.isdigit()': True,\n",
              " 'postag': 'CD',\n",
              " 'postag[:2]': 'CD',\n",
              " 'BOS': True,\n",
              " '+1:word.lower()': ':',\n",
              " '+1:word.istitle()': False,\n",
              " '+1:word.isupper()': False,\n",
              " '+1:postag': ':',\n",
              " '+1:postag[:2]': ':',\n",
              " '+1:word2vec': 0,\n",
              " '+2:word.lower()': '41',\n",
              " '+2:word.istitle()': False,\n",
              " '+2:word.isupper()': False,\n",
              " '+2:postag': 'CD',\n",
              " '+2:postag[:2]': 'CD',\n",
              " '+2:word2vec': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_train, y_train, X_test, y_test = utils.create_features(train, test, word2vec=WORD2VEC,dist=2)\n",
        "\n",
        "X_train[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d9a10736-d612-4444-90df-3a66ea78bb31",
      "metadata": {
        "id": "d9a10736-d612-4444-90df-3a66ea78bb31"
      },
      "outputs": [],
      "source": [
        "crf = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=False,\n",
        ")\n",
        "\n",
        "crf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = crf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ebba1bc6-9c6e-4916-a133-855334ab1140",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "ebba1bc6-9c6e-4916-a133-855334ab1140",
        "outputId": "d9fb0789-7313-4796-e66d-b985f46819a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3fbe9314eae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinarized_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mexplain_weights\u001b[0;34m(crf, html, top)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexplain_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_weights_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/eli5/ipython.py\u001b[0m in \u001b[0;36mshow_weights\u001b[0;34m(estimator, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0mformat_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplain_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mexpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexplain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0m_set_html_kwargs_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_as_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    873\u001b[0m                             '1 positional argument')\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/eli5/sklearn_crfsuite/explain_weights.py\u001b[0m in \u001b[0;36mexplain_weights_sklearn_crfsuite\u001b[0;34m(crf, top, target_names, targets, feature_re, feature_filter)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mcoef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransition_coef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         ),\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CRF'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    277\u001b[0m         )\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mrepr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0msio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0m\u001b[1;32m    405\u001b[0m                                                 self._depth, level)\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return _safe_repr(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_changed_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     91\u001b[0m     estimator with non-default values.\"\"\"\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0minit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"deprecated_original\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mdeep_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
          ]
        }
      ],
      "source": [
        "display(utils.explain_weights(crf, html=True))\n",
        "utils.print_classification_report(predictions, y_test)\n",
        "utils.binarized_confusion_matrix(predictions, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dDiwKMdnPal"
      },
      "id": "1dDiwKMdnPal",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}